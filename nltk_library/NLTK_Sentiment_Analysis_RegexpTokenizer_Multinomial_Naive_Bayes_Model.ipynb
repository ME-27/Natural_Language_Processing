{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a73e8859",
   "metadata": {},
   "source": [
    "# NLTK; Sentiment Analysis; RegexpTokenizer; Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbb7e5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65c65634",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer  # Regular Exression Tokenizer - it tokenizes text and can remove symbols!!!\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0476629d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\fross\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "daadef9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [\"This %%*was awesome an awesome movie\", \n",
    "           \"Great movie! I liked it a lot\", \n",
    "           \"Happy Ending! awesome acting by the hero\", \n",
    "           \"loved it! truly great\", \n",
    "           \"bad not upto the mark\", \n",
    "           \"could have been better\", \n",
    "           \"Surrely a Disappointing movie\"]\n",
    "\n",
    "y_train = [1, 1, 1, 1, 0, 0, 0]\n",
    "\n",
    "X_test = [\"I was happy & happy and I loved the acting in the movie\", \n",
    "          \"The movie I saw was bad\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac85559",
   "metadata": {},
   "source": [
    "### data cleaning; RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cc39479",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')  # r'\\w+' means that we want words and we want to concatinate those words\n",
    "en_stopwords = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f48803ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cleaned_data(text):\n",
    "    text = text.lower()\n",
    "    \n",
    "    # tokenization\n",
    "    tokens = tokenizer.tokenize(text)  # RegexpTokenizer!!!\n",
    "    \n",
    "    # removing stopwords\n",
    "    tokens_without_stopwords = [_ for _ in tokens if _ not in en_stopwords]\n",
    "    \n",
    "    # stemming\n",
    "    stemmed_tokens_without_stopwords = [ps.stem(_) for _ in tokens_without_stopwords]\n",
    "    \n",
    "    # convertion from a list back into a string\n",
    "    cleaned_text = ' '.join(stemmed_tokens_without_stopwords)\n",
    "    \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b015c5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cleaned = [get_cleaned_data(_) for _ in X_train]\n",
    "X_test_cleaned = [get_cleaned_data(_) for _ in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c731471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['awesom awesom movi',\n",
       " 'great movi like lot',\n",
       " 'happi end awesom act hero',\n",
       " 'love truli great',\n",
       " 'bad upto mark',\n",
       " 'could better',\n",
       " 'surr disappoint movi']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a198ab20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['happi happi love act movi', 'movi saw bad']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb892b1",
   "metadata": {},
   "source": [
    "### vectorization; ngram use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fe3f1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fe43275",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(ngram_range=(1, 2))  # !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f3d46a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7x34 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 38 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectorization of X_train\n",
    "X_train_cleaned_vectorized = cv.fit_transform(X_train_cleaned)  # .toarray()\n",
    "X_train_cleaned_vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5f5b582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['act', 'act hero', 'awesom', 'awesom act', 'awesom awesom',\n",
       "       'awesom movi', 'bad', 'bad upto', 'better', 'could',\n",
       "       'could better', 'disappoint', 'disappoint movi', 'end',\n",
       "       'end awesom', 'great', 'great movi', 'happi', 'happi end', 'hero',\n",
       "       'like', 'like lot', 'lot', 'love', 'love truli', 'mark', 'movi',\n",
       "       'movi like', 'surr', 'surr disappoint', 'truli', 'truli great',\n",
       "       'upto', 'upto mark'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e94d7aaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2x34 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 6 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectorization of X_test\n",
    "X_test_cleaned_vectorized = cv.transform(X_test_cleaned)  # .toarray()\n",
    "X_test_cleaned_vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b9c0ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06efce95",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes as our prediction model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5a2e31",
   "metadata": {},
   "source": [
    "Multinomial Naive Bayes explained - https://www.youtube.com/watch?v=O2L2Uv9pdDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82007f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96edb1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5f6fdb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.fit(X_train_cleaned_vectorized, y_train)  # MultinomialNB() can consume not only array, but sparse matrix too!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b3d483",
   "metadata": {},
   "source": [
    "### prediction on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8b699e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.predict(X_train_cleaned_vectorized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ec8c04",
   "metadata": {},
   "source": [
    "### prediction on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4abc96a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.predict(X_test_cleaned_vectorized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1218e1b",
   "metadata": {},
   "source": [
    "### cheking predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35986d54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I was happy & happy and I loved the acting in the movie',\n",
       " 'The movie I saw was bad']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fae6bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4c0e61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e41acb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
